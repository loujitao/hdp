a1.sources = r1
a1.sinks = s1
a1.channels = c1

# 配置source组件
a1.sources.r1.type = spooldir
# #此处配置监听变化的日志文件dir
a1.sources.r1.spoolDir = /home/hadoop/test/flume
a1.sources.r1.fileSuffix = .COMPLETED
a1.sources.r1.fileHeader = true
# #忽略所有以.tmp结尾的文件，不上传
a1.sources.r1.ignorePattern = ([^ ]*\.tmp)
  
#  # 配置sink组件   HDFS sink涉及小文件优化等问题
a1.sinks.s1.type = hdfs
a1.sinks.s1.hdfs.path = hdfs://hdp001:9000/flume/upload/%Y%m%d/%H
#  #上传文件的前缀
a1.sinks.s1.hdfs.filePrefix = upload-
#是否按照时间滚动文件夹
a1.sinks.s1.hdfs.round = true
#多少时间单位创建一个新的文件夹
a1.sinks.s1.hdfs.roundValue = 1
#重新定义时间单位
a1.sinks.s1.hdfs.roundUnit = hour
#是否使用本地时间戳
a1.sinks.s1.hdfs.useLocalTimeStamp = true
#积攒多少哥Event才flush到HDFS一次
a1.sinks.s1.hdfs.batchSize = 1000
#设置文件类型，可支持压缩
a1.sinks.s1.hdfs.fileType = DataStream
#多久生成一个新的文件
a1.sinks.s1.hdfs.rollInterval = 60
#设置每个文件的滚动大小
a1.sinks.s1.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
a1.sinks.s1.hdfs.rollCount = 0

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
 
# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.s1.channel = c1 
