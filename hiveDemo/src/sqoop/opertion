原理和机制
将导入或导出命令翻译成mapreduce程序来实现。在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。

#sqoop验证连接MySQL，成功会显示MySQL中的库
bin/sqoop list-databases --connect jdbc:mysql://hdp001:3306/ --username root --password 123456

1）========mysql导入HDFS    sqoop导入import
#全部导入
bin/sqoop import \
--connect jdbc:mysql://hdp001:3306/company \
--username root \
--password 123456 \
--table staff \
--target-dir /user/company \
--delete-target-dir \
--num-mappers 1 \
--fields-terminated-by "\t"


#查询导入  如果query后面使用双引号，则$CONDITIONS前必须加转移符
bin/sqoop import \
--connect jdbc:mysql://hdp001:3306/company \
--username root \
--password 123456 \
--target-dir /user/company \
--delete-target-dir \
--num-mappers 1 \
--fields-terminated-by "\t" \
--query 'select name,sex from staff where id <=1 and $CONDITIONS;'

#导入指定的列
bin/sqoop import \
--connect jdbc:mysql://hdp001:3306/company \
--username root \
--password 123456 \
--target-dir /user/company \
--delete-target-dir \
--num-mappers 1 \
--fields-terminated-by "\t" \
--columns id,sex \
--table staff

#使用sqoop关键字筛选查询导入数据
 bin/sqoop import \
--connect jdbc:mysql://hdp001:3306/company \
--username root \
--password 123456 \
--target-dir /user/company \
--delete-target-dir \
--num-mappers 1 \
--fields-terminated-by "\t" \
--table staff \
--where "id=1"


2）========mysql导入hive
#底层先导入HDFS，然后将数据迁移到hive表（不指定库名，用配置里的默认库default）
bin/sqoop import \
--connect jdbc:mysql://hdp001:3306/company \
--username root \
--password 123456 \
--table staff \
--num-mappers 1 \
--hive-import \
--fields-terminated-by "\t" \
--hive-overwrite \
--hive-table staff_hive


3）========mysql导入hbase
bin/sqoop import \
--connect jdbc:mysql://hdp001:3306/company \
--username root \
--password 123456 \
--table staff \
--columns "id,name,sex" \
--column-family "info" \
--hbase-create-table \
--hbase-row-key "id" \
--hbase-table "hbase_company" \
--num-mappers 1 \
--split-by id



导出   使用export关键字
1)========HIVE/HDFS  导出到  RDBMS
bin/sqoop export \
--connect jdbc:mysql://hdp001:3306/company \
--username root \
--password 123456 \
--table staff \
--num-mappers 1 \
--export-dir /user/hive/warehouse/staff_hive \
--input-fields-terminated-by "\t"

