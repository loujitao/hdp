hive sql优化

1）Fetch抓取，Hive中对某些情况的查询可以不必使用MapReduce计算
set hive.fetch.task.conversion=more;

2）小表join大表，开启map join功能
set hive.auto.convert.join = true;

3)大表join大表时
#=================空KEY过滤
# 某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。数据倾斜问题

#过滤前：
insert overwrite table jointable
select n.* from nullidtable n
left join ori o on n.id = o.id;

#过滤后：     增加一个子查询
insert overwrite table jointable
select n.* from (
	select * from nullidtable where id is not null
	) n
left join ori o on n.id = o.id;

#=================空key转换
#有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，
#此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。

#过滤前：
insert overwrite table jointable
select n.* from nullidtable n
left join ori b on n.id = b.id;

#过滤后：
insert overwrite table jointable
select n.* from nullidtable n
full join ori o on
case when n.id is null
	then concat('hive', rand())
	else n.id end = o.id;


4）mapJoin
#小表join大表
#在Reduce阶段完成join。容易发生数据倾斜。可以用MapJoin把小表全部加载到内存在map端进行join，避免reducer处理
#设置自动选择Mapjoin
set hive.auto.convert.join = true; 默认为true

#大表小表的阈值设置（默认25M一下认为是小表）：
set hive.mapjoin.smalltable.filesize=25000000;


5）group by
#========开启Map端聚合参数设置
#是否在Map端进行聚合，默认为True
set hive.map.aggr = true

#在Map端进行聚合操作的条目数目
set hive.groupby.mapaggr.checkinterval = 100000

#有数据倾斜的时候进行负载均衡（默认是false）
set hive.groupby.skewindata = true

当选项设定为 true，生成的查询计划会有两个MR Job。
第一个MRJob中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；
第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。

6） Count(Distinct) 去重统计
#由于COUNT DISTINCT的全聚合操作，即使设定了reduce task个数，
#set mapred.reduce.tasks=100；hive也只会启动一个reducer。

#一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换：
#去重查询优化前：
select count(distinct id) from bigtable;

#采用GROUP by去重id
select count(id) from (
	select id from bigtable group by id ) a;

7）避免笛卡尔积的join
# join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。

8）行列过滤
#列处理：
#		在SELECT中，只拿需要的列，如果有，尽量使用分区过滤，少用SELECT *。

#行处理：
#		在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤，
#优化前：
select o.id from bigtable b
join ori o on o.id = b.id
where o.id <= 10;

#优化后：
select b.id from bigtable b
join (
	select id from ori where id <= 10) o
on b.id = o.id;


==================== 配置优化：
1）小文件进行合并
#在map执行前合并小文件，减少map数：
#CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。
set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;

#在map任务结束时合并小文件，默认true
SET hive.merge.mapfiles = true;

#在reduce任务结束时合并小文件，默认false
SET hive.merge.mapredfiles = true;

#合并文件的大小，默认256M
SET hive.merge.size.per.task = 268435456;

#当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge
SET hive.merge.smallfiles.avgsize = 16777216;


2)合理设置Reduce数
#设置每个job的Reduce个数
set mapreduce.job.reduces = 15;

#在设置reduce个数的时候也需要考虑这两个原则：
	处理大数据量利用合适的reduce数；
	使单个reduce任务处理数据量大小要合适；


3） 并行执行	Hive会将一个查询转化成一个或者多个阶段。
#这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。
#或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段
# 如果有更多的阶段可以并行执行，那么job可能就越快完成。

#通过设置参数hive.exec.parallel值为true，就可以开启并发执行。
set hive.exec.parallel=true;              //打开任务并行执行
set hive.exec.parallel.thread.number=16;  //同一个sql允许最大并行度，默认为8。


4)JVM重用
# JVM重用可以使得JVM实例在同一个job中重新使用N次。
# N的值可以在Hadoop的mapred-site.xml文件中进行配置。
# 通常在10-20之间，具体多少需要根据具体业务场景测试得出。
	<property>
	  <name>mapreduce.job.jvm.numtasks</name>
	  <value>10</value>
	</property>
这个功能的缺点是，开启JVM重用将一直占用使用到的task插槽，以便进行重用，直到任务完成后才能释放。


5）执行计划查看
# 基本语法		EXPLAIN [EXTENDED | DEPENDENCY | AUTHORIZATION] query

explain select * from emp;
explain extended select * from emp;